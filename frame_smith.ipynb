{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Reference\n",
        "* [video1](https://www.youtube.com/watch?v=ymgGr1_M-xY)\n",
        "* [video2](https://www.youtube.com/watch?v=ktNbvuMuajk)\n",
        "* [github-frameSmith](https://github.com/tmk1221/frameSmith)"
      ],
      "metadata": {
        "id": "bv3pwOHnzgoJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wp3YwXxStUfx",
        "outputId": "f9e0397c-9888-4c98-98c5-68bd173313f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'frameSmith'...\n",
            "remote: Enumerating objects: 128, done.\u001b[K\n",
            "remote: Total 128 (delta 0), reused 0 (delta 0), pack-reused 128 (from 2)\u001b[K\n",
            "Receiving objects: 100% (128/128), 300.43 KiB | 1.18 MiB/s, done.\n",
            "Resolving deltas: 100% (72/72), done.\n",
            "/content/frameSmith\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/tmk1221/frameSmith\n",
        "%cd frameSmith"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# create .env file and save keys to it"
      ],
      "metadata": {
        "id": "kregPLTEhPmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile .env\n",
        "OPENAI_API_KEY=\"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\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gFnF_QLtr4B",
        "outputId": "4a6e0073-b3ad-40d8-f0bb-d05c0ee1a12d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting .env\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt --quiet"
      ],
      "metadata": {
        "id": "HbVRGeIitbkO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b33acdf-67de-4ad2-9273-58c773195254"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/147.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.5/75.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.5/415.5 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m618.8/618.8 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for chroma-hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-core 0.3.29 requires langsmith<0.3,>=0.1.125, but you have langsmith 0.0.92 which is incompatible.\n",
            "langchain-core 0.3.29 requires pydantic<3.0.0,>=2.5.2; python_full_version < \"3.12.4\", but you have pydantic 1.10.9 which is incompatible.\n",
            "albumentations 1.4.20 requires pydantic>=2.7.0, but you have pydantic 1.10.9 which is incompatible.\n",
            "wandb 0.19.2 requires pydantic<3,>=2.6, but you have pydantic 1.10.9 which is incompatible.\n",
            "google-genai 0.3.0 requires pydantic<3.0.0dev,>=2.0.0, but you have pydantic 1.10.9 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!playwright install"
      ],
      "metadata": {
        "id": "dVIPZgG4ueMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Re-write the debugged code\n",
        "replaced line 30 from:\n",
        "\n",
        " previous (error) line `loader = YoutubeLoader.from_youtube_url(video_url, add_video_info=True)`\n",
        "\n",
        " new (debugged) line `loader = YoutubeLoader.from_youtube_url(video_url)`\n"
      ],
      "metadata": {
        "id": "DEuv2gnvhYQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/framework_generator.py\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.document_loaders import YoutubeLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import AsyncChromiumLoader\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "import csv\n",
        "from clean_scrape import extract_clean_text, remove_extra_newlines_and_tabs\n",
        "\n",
        "# Generates a Framework\n",
        "def framer(product, framework_questions, prompt_template, openai_model, news_urls, youtube_urls=None):\n",
        "\n",
        "   # Load in News\n",
        "    loader = AsyncChromiumLoader(news_urls)\n",
        "    docs = loader.load()\n",
        "\n",
        "    # Remove extra HTML tags from articles\n",
        "    for doc in docs:\n",
        "        cleaned_text = extract_clean_text(doc.page_content)\n",
        "        cleaned_text = remove_extra_newlines_and_tabs(cleaned_text)\n",
        "        doc.page_content = cleaned_text\n",
        "\n",
        "    # Load in YouTube videos\n",
        "    if youtube_urls is not None:\n",
        "        for video_url in youtube_urls:\n",
        "            loader = YoutubeLoader.from_youtube_url(video_url)\n",
        "            youtube = loader.load()\n",
        "            if youtube == []:\n",
        "                \"Transcript not available for video: \" + video_url\n",
        "            else:\n",
        "                docs.append(youtube[0])\n",
        "\n",
        "    #Print cleaned texts to ensure they were scraped and cleaned properly\n",
        "    #print(docs)\n",
        "\n",
        "    print(\"Data sources loaded\")\n",
        "\n",
        "    # Split documents into 1000 character chunks\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000)\n",
        "    texts = splitter.split_documents(docs)\n",
        "\n",
        "    print(\"Splitting articles into 1000 character chunks\")\n",
        "\n",
        "    # Embed each document chunk for search/retrieval\n",
        "    embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "    docsearch = Chroma.from_documents(texts, embeddings)\n",
        "\n",
        "    print(\"Embedding each article chunk for later search and retrieval\")\n",
        "\n",
        "    # Setup chains\n",
        "    llm = ChatOpenAI(temperature=0, model=openai_model)\n",
        "\n",
        "    template = prompt_template\n",
        "\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"chat_history\", \"human_input\", \"context\"], template=template, partial_variables={\"product\": product}\n",
        "    )\n",
        "    memory = ConversationBufferWindowMemory(k=1, memory_key=\"chat_history\", input_key=\"human_input\")\n",
        "    chain = load_qa_chain(\n",
        "        llm, chain_type=\"stuff\", memory=memory, prompt=prompt\n",
        "    )\n",
        "\n",
        "    # Framework questions\n",
        "    queries = framework_questions\n",
        "\n",
        "    # Generate Framework\n",
        "    results = {}\n",
        "    for key, query in queries.items():\n",
        "        docs = docsearch.similarity_search(query)\n",
        "        result = chain({\"input_documents\": docs, \"human_input\": query}, return_only_outputs=True)\n",
        "\n",
        "        results[key] = result\n",
        "        print(f\"✅ {key.replace('_', ' ').capitalize()}\")\n",
        "\n",
        "    # Write to CSV\n",
        "    filename = f\"./framework_output/{product}_framework.csv\"\n",
        "\n",
        "    print(\"Writing to filename: \", filename)\n",
        "\n",
        "    with open(filename, 'w', newline='') as csv_file:\n",
        "        csv_writer = csv.writer(csv_file)\n",
        "        csv_writer.writerow([\"Section\", \"Details\"])\n",
        "        for key, value in results.items():\n",
        "            csv_writer.writerow([key.replace('_', ' ').capitalize(), value])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4V2bDIWwWXa",
        "outputId": "3d6e3e55-068b-451d-9c74-f080917c341f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting src/framework_generator.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 src/generate.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wj_AJs7Czby4",
        "outputId": "8e9526c6-cd71-4dfc-d137-75ad9ec4ab6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data sources loaded\n",
            "Splitting articles into 1000 character chunks\n",
            "Embedding each article chunk for later search and retrieval\n",
            "✅ Overall\n",
            "✅ Target users\n",
            "✅ Problems\n",
            "✅ Solutions\n",
            "✅ Unfair advantage\n",
            "✅ Unique value proposition\n",
            "✅ Channels\n",
            "✅ Costs\n",
            "✅ Revenue\n",
            "Writing to filename:  ./framework_output/Asimov_framework.csv\n",
            "Execution time: 83.46 seconds\n"
          ]
        }
      ]
    }
  ]
}